"""
è‡ªä¸»æµ‹è¯•å…¥å£è„šæœ¬
æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼Œå¯ç‹¬ç«‹è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹
"""

import argparse
import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

_project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(_project_root / "src"))
sys.path.insert(0, str(_project_root))

from tests.autonomous.autonomous_test_runner import AutonomousTestRunner, TestConfig  # noqa: E402


def setup_logging(log_level: str = "INFO", log_file: str = None):
    """è®¾ç½®æ—¥å¿—"""
    import io

    if sys.platform == "win32":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

    level = getattr(logging, log_level.upper(), logging.INFO)

    handlers = []

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(
        logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    )
    handlers.append(console_handler)

    if log_file:
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(log_file, encoding="utf-8")
        file_handler.setFormatter(
            logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        )
        handlers.append(file_handler)

    logging.basicConfig(level=level, handlers=handlers)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="MS Rewards Automator - è‡ªä¸»æµ‹è¯•æ¡†æ¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python run_autonomous_tests.py                           # è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
  python run_autonomous_tests.py --integrated              # é›†æˆæµ‹è¯•ï¼ˆå¼€å‘æ¨¡å¼ï¼Œå¿«é€Ÿè°ƒè¯•ï¼‰
  python run_autonomous_tests.py --integrated --user-mode  # é›†æˆæµ‹è¯•ï¼ˆç”¨æˆ·æ¨¡å¼ï¼Œå¯ç”¨é˜²æ£€æµ‹ï¼‰
  python run_autonomous_tests.py --headless                # æ— å¤´æ¨¡å¼è¿è¡Œ
  python run_autonomous_tests.py --quick                   # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
  python run_autonomous_tests.py --test login              # ä»…è¿è¡Œç™»å½•æµ‹è¯•
  python run_autonomous_tests.py --no-screenshot           # ç¦ç”¨è‡ªåŠ¨æˆªå›¾
  python run_autonomous_tests.py --report-only             # ä»…ç”ŸæˆæŠ¥å‘Š

æµ‹è¯•ç±»å‹:
  login        - ç™»å½•çŠ¶æ€æ£€æµ‹
  bing_access  - Bingè®¿é—®æµ‹è¯•
  search       - æœç´¢åŠŸèƒ½æµ‹è¯•
  points       - ç§¯åˆ†æ£€æµ‹æµ‹è¯•
  full         - å®Œæ•´æµ‹è¯•å¥—ä»¶ï¼ˆé»˜è®¤ï¼‰
  integrated   - é›†æˆæµ‹è¯•ï¼ˆå¤ç”¨ MSRewardsAppï¼‰

æµ‹è¯•æ¨¡å¼:
  --dev        - å¼€å‘æ¨¡å¼ï¼šå¿«é€Ÿè°ƒè¯•ï¼Œç¦ç”¨é˜²æ£€æµ‹ï¼Œ2+2æœç´¢
  --user-mode  - ç”¨æˆ·æ¨¡å¼ï¼šé²æ£’æ€§æµ‹è¯•ï¼Œå¯ç”¨é˜²æ£€æµ‹ï¼Œ3+3æœç´¢
        """,
    )

    parser.add_argument("--config", default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)")

    parser.add_argument(
        "--headless", action="store_true", default=True, help="æ— å¤´æ¨¡å¼è¿è¡Œ (é»˜è®¤: True)"
    )

    parser.add_argument("--no-headless", action="store_true", help="æ˜¾ç¤ºæµè§ˆå™¨çª—å£")

    parser.add_argument(
        "--test",
        choices=["login", "bing_access", "search", "points", "full", "integrated"],
        default="full",
        help="è¦è¿è¡Œçš„æµ‹è¯•ç±»å‹ (é»˜è®¤: full)",
    )

    parser.add_argument(
        "--integrated", action="store_true", help="è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆå¤ç”¨ MSRewardsApp æ‰§è¡Œå®Œæ•´æµç¨‹ï¼‰"
    )

    parser.add_argument(
        "--user-mode",
        action="store_true",
        help="ç”¨æˆ·æ¨¡å¼æµ‹è¯•ï¼ˆå¯ç”¨é˜²æ£€æµ‹ï¼Œæ¨¡æ‹ŸçœŸå®ç¯å¢ƒï¼Œæœ‰å¤´æ¨¡å¼ï¼‰",
    )

    parser.add_argument(
        "--dev", action="store_true", help="å¼€å‘æ¨¡å¼æµ‹è¯•ï¼ˆå¿«é€Ÿè°ƒè¯•ï¼Œç¦ç”¨é˜²æ£€æµ‹ï¼Œæœ‰å¤´æ¨¡å¼ï¼‰"
    )

    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå‡å°‘ç­‰å¾…æ—¶é—´ï¼‰")

    parser.add_argument("--no-screenshot", action="store_true", help="ç¦ç”¨è‡ªåŠ¨æˆªå›¾")

    parser.add_argument(
        "--screenshot-on-error",
        action="store_true",
        default=True,
        help="ä»…åœ¨é”™è¯¯æ—¶æˆªå›¾ (é»˜è®¤: True)",
    )

    parser.add_argument(
        "--stop-on-critical",
        action="store_true",
        default=True,
        help="å‘ç°ä¸¥é‡é—®é¢˜æ—¶åœæ­¢æµ‹è¯• (é»˜è®¤: True)",
    )

    parser.add_argument("--max-retries", type=int, default=3, help="æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)")

    parser.add_argument(
        "--timeout", type=int, default=30000, help="é¡µé¢è¶…æ—¶æ—¶é—´(æ¯«ç§’) (é»˜è®¤: 30000)"
    )

    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)",
    )

    parser.add_argument("--log-file", default=None, help="æ—¥å¿—æ–‡ä»¶è·¯å¾„")

    parser.add_argument("--report-only", action="store_true", help="ä»…ç”ŸæˆæŠ¥å‘Šï¼ˆä¸è¿è¡Œæµ‹è¯•ï¼‰")

    parser.add_argument(
        "--output-dir", default="logs/test_reports", help="æŠ¥å‘Šè¾“å‡ºç›®å½• (é»˜è®¤: logs/test_reports)"
    )

    parser.add_argument("--cleanup", action="store_true", help="æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®ï¼ˆä¿ç•™æœ€è¿‘5æ¬¡ï¼‰")

    parser.add_argument("--keep-reports", type=int, default=5, help="ä¿ç•™æœ€è¿‘Næ¬¡æµ‹è¯•æŠ¥å‘Š (é»˜è®¤: 5)")

    return parser.parse_args()


def cleanup_old_test_data(keep_count: int = 5):
    """æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®"""
    import shutil

    base_dir = Path("logs")
    dirs_to_clean = ["test_reports", "screenshots"]

    cleaned = 0

    for dir_name in dirs_to_clean:
        target_dir = base_dir / dir_name
        if not target_dir.exists():
            continue

        subdirs = sorted(
            [d for d in target_dir.iterdir() if d.is_dir()],
            key=lambda x: x.stat().st_mtime,
            reverse=True,
        )

        for old_dir in subdirs[keep_count:]:
            try:
                shutil.rmtree(old_dir)
                cleaned += 1
                print(f"å·²æ¸…ç†: {old_dir}")
            except Exception as e:
                print(f"æ¸…ç†å¤±è´¥ {old_dir}: {e}")

    files_to_clean = ["diagnosis_report.json"]
    for file_name in files_to_clean:
        file_path = base_dir / file_name
        if file_path.exists():
            try:
                file_path.unlink()
            except Exception:
                pass

    if cleaned > 0:
        print(f"\nå·²æ¸…ç† {cleaned} ä¸ªæ—§æµ‹è¯•ç›®å½•")
    else:
        print("\næ— éœ€æ¸…ç†")

    return cleaned


async def run_single_test(runner: AutonomousTestRunner, test_type: str) -> bool:
    """è¿è¡Œå•ä¸ªæµ‹è¯•"""
    test_map = {
        "login": ("ç™»å½•çŠ¶æ€æ£€æµ‹", runner._test_login_status),
        "bing_access": ("Bingè®¿é—®æµ‹è¯•", runner._test_bing_access),
        "search": ("æœç´¢åŠŸèƒ½æµ‹è¯•", runner._test_search_function),
        "points": ("ç§¯åˆ†æ£€æµ‹æµ‹è¯•", runner._test_points_detection),
    }

    if test_type in test_map:
        name, test_func = test_map[test_type]
        return await runner.run_test(name, test_func)

    return False


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    setup_logging(args.log_level, args.log_file)
    logger = logging.getLogger(__name__)

    if args.cleanup:
        print("\næ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®...")
        cleanup_old_test_data(args.keep_reports)
        print("")

    print("\n" + "=" * 70)
    print("MS Rewards Automator - è‡ªä¸»æµ‹è¯•æ¡†æ¶")
    print("=" * 70)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"æµ‹è¯•ç±»å‹: {args.test}")

    if args.integrated:
        mode_str = "ç”¨æˆ·æ¨¡å¼ï¼ˆå¯ç”¨é˜²æ£€æµ‹ï¼‰" if args.user_mode else "å¼€å‘æ¨¡å¼ï¼ˆå¿«é€Ÿè°ƒè¯•ï¼‰"
        print(f"æµ‹è¯•æ¨¡å¼: é›†æˆæµ‹è¯• - {mode_str}")
    else:
        print(f"æ— å¤´æ¨¡å¼: {not args.no_headless}")

    print("=" * 70)

    if args.integrated or args.test == "integrated":
        return await run_integrated_test_mode(args)

    test_config = TestConfig(
        headless=not args.no_headless,
        auto_screenshot=not args.no_screenshot,
        screenshot_on_error=args.screenshot_on_error,
        stop_on_critical=args.stop_on_critical,
        max_retries=args.max_retries,
        page_timeout=args.timeout,
        inspection_interval=3 if args.quick else 5,
    )

    runner = AutonomousTestRunner(config_path=args.config, test_config=test_config)

    runner.reporter.output_dir = Path(args.output_dir)

    results = {"session_id": runner.screenshot_manager.session_id, "tests": {}, "reports": {}}

    try:
        if not await runner.initialize():
            logger.error("åˆå§‹åŒ–å¤±è´¥")
            return 1

        if not await runner.create_browser():
            logger.error("åˆ›å»ºæµè§ˆå™¨å¤±è´¥")
            return 1

        storage_state = runner.config.get("account.storage_state_path")
        if not await runner.create_context(storage_state):
            logger.error("åˆ›å»ºä¸Šä¸‹æ–‡å¤±è´¥")
            return 1

        if args.test == "full":
            results["tests"]["login"] = await runner.run_test(
                "ç™»å½•çŠ¶æ€æ£€æµ‹", runner._test_login_status
            )

            results["tests"]["bing_access"] = await runner.run_test(
                "Bingè®¿é—®æµ‹è¯•", runner._test_bing_access
            )

            results["tests"]["search_function"] = await runner.run_test(
                "æœç´¢åŠŸèƒ½æµ‹è¯•", runner._test_search_function
            )

            results["tests"]["points_detection"] = await runner.run_test(
                "ç§¯åˆ†æ£€æµ‹æµ‹è¯•", runner._test_points_detection
            )
        else:
            results["tests"][args.test] = await run_single_test(runner, args.test)

    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        results["interrupted"] = True

    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        results["error"] = str(e)

    finally:
        await runner.cleanup()

    results["reports"] = runner.generate_reports()

    print_results(results)

    passed = sum(1 for v in results["tests"].values() if v)
    total = len(results["tests"])

    if passed == total and total > 0:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šäº†è§£è¯¦æƒ…")
        return 1


async def run_integrated_test_mode(args):
    """è¿è¡Œé›†æˆæµ‹è¯•æ¨¡å¼"""
    from tests.autonomous.integrated_test_runner import IntegratedTestRunner

    user_mode = args.user_mode
    mode_str = "ç”¨æˆ·æ¨¡å¼ï¼ˆå¯ç”¨é˜²æ£€æµ‹ï¼‰" if user_mode else "å¼€å‘æ¨¡å¼ï¼ˆå¿«é€Ÿè°ƒè¯•ï¼‰"

    print(f"\nğŸš€ è¿è¡Œé›†æˆæµ‹è¯• - {mode_str}")
    print("-" * 70)

    runner = IntegratedTestRunner(config_path=args.config, user_mode=user_mode)

    try:
        results = await runner.run_full_test()
    except Exception as e:
        print(f"\nâŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1

    print_results(results)

    if results["tests"].get("full_test"):
        print("\nâœ… é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("\nâš ï¸ é›†æˆæµ‹è¯•å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šäº†è§£è¯¦æƒ…")
        return 1


def print_results(results: dict[str, Any]):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 70)

    passed = sum(1 for v in results["tests"].values() if v)
    total = len(results["tests"])

    for test_name, test_result in results["tests"].items():
        status = "âœ… é€šè¿‡" if test_result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")

    print("\n" + "-" * 70)
    print(f"æ€»è®¡: {total} | é€šè¿‡: {passed} | å¤±è´¥: {total - passed}")

    if results.get("reports"):
        print("\næŠ¥å‘Šæ–‡ä»¶:")
        for report_type, path in results["reports"].items():
            print(f"  {report_type}: {path}")

    print("=" * 70)


async def run_integrated_test(
    config_path: str = "config.yaml", user_mode: bool = False
) -> dict[str, Any]:
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    from tests.autonomous.integrated_test_runner import IntegratedTestRunner

    runner = IntegratedTestRunner(config_path, user_mode=user_mode)
    return await runner.run_full_test()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
